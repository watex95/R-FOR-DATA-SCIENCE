% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Predict the number of applications received using the other variables in the College data set in library ISLR},
  pdfauthor={student},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Predict the number of applications received using the other variables in
the College data set in library ISLR}
\author{student}
\date{1/30/2020}

\begin{document}
\frame{\titlepage}

\begin{frame}[fragile]{(a) Split the data set into a training set and a
test set using caret library and fit each of the following models using
caret and ten fold cross validation.}
\protect\hypertarget{a-split-the-data-set-into-a-training-set-and-a-test-set-using-caret-library-and-fit-each-of-the-following-models-using-caret-and-ten-fold-cross-validation.}{}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ISLR)}
\KeywordTok{library}\NormalTok{(glmnet)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: Matrix
\end{verbatim}

\begin{verbatim}
## Loaded glmnet 3.0-2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{attach}\NormalTok{(College)}
\KeywordTok{head}\NormalTok{(College)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                              Private Apps Accept Enroll Top10perc Top25perc
## Abilene Christian University     Yes 1660   1232    721        23        52
## Adelphi University               Yes 2186   1924    512        16        29
## Adrian College                   Yes 1428   1097    336        22        50
## Agnes Scott College              Yes  417    349    137        60        89
## Alaska Pacific University        Yes  193    146     55        16        44
## Albertson College                Yes  587    479    158        38        62
##                              F.Undergrad P.Undergrad Outstate Room.Board Books
## Abilene Christian University        2885         537     7440       3300   450
## Adelphi University                  2683        1227    12280       6450   750
## Adrian College                      1036          99    11250       3750   400
## Agnes Scott College                  510          63    12960       5450   450
## Alaska Pacific University            249         869     7560       4120   800
## Albertson College                    678          41    13500       3335   500
##                              Personal PhD Terminal S.F.Ratio perc.alumni Expend
## Abilene Christian University     2200  70       78      18.1          12   7041
## Adelphi University               1500  29       30      12.2          16  10527
## Adrian College                   1165  53       66      12.9          30   8735
## Agnes Scott College               875  92       97       7.7          37  19016
## Alaska Pacific University        1500  76       72      11.9           2  10922
## Albertson College                 675  67       73       9.4          11   9727
##                              Grad.Rate
## Abilene Christian University        60
## Adelphi University                  56
## Adrian College                      54
## Agnes Scott College                 59
## Alaska Pacific University           15
## Albertson College                   55
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{model.matrix}\NormalTok{(Apps}\OperatorTok{~}\NormalTok{., College)[,}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\NormalTok{y <-}\StringTok{ }\NormalTok{College}\OperatorTok{$}\NormalTok{Apps}
\NormalTok{lambda <-}\StringTok{ }\DecValTok{10}\OperatorTok{^}\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{-2}\NormalTok{, }\DataTypeTok{length =} \DecValTok{100}\NormalTok{)}


\CommentTok{# Train test split}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{489}\NormalTok{)}
\NormalTok{train =}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(x), }\KeywordTok{nrow}\NormalTok{(x)}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\NormalTok{test =}\StringTok{ }\NormalTok{(}\OperatorTok{-}\NormalTok{train)}
\NormalTok{ytest =}\StringTok{ }\NormalTok{y[test]}
\end{Highlighting}
\end{Shaded}

\end{frame}

\begin{frame}[fragile]{(b) Fit a linear model using ordinary least
squares on the training set, and report the test mean squared error
obtained.}
\protect\hypertarget{b-fit-a-linear-model-using-ordinary-least-squares-on-the-training-set-and-report-the-test-mean-squared-error-obtained.}{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{OLS_lm <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Apps}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ College, }\DataTypeTok{subset =}\NormalTok{ train)}
\NormalTok{OLS_lm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Apps ~ ., data = College, subset = train)
## 
## Coefficients:
## (Intercept)   PrivateYes       Accept       Enroll    Top10perc    Top25perc  
##  -544.41744   -170.52279      1.74160     -1.41087     38.28257     -6.06587  
## F.Undergrad  P.Undergrad     Outstate   Room.Board        Books     Personal  
##     0.07306      0.08748     -0.08632      0.16650      0.06319      0.09351  
##         PhD     Terminal    S.F.Ratio  perc.alumni       Expend    Grad.Rate  
##   -11.10782      2.19668      4.12585      3.56206      0.05095      1.92934
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Find the best lambda from our list via cross-validation}
\NormalTok{cv.out <-}\StringTok{ }\KeywordTok{cv.glmnet}\NormalTok{(x[train,], y[train], }\DataTypeTok{alpha =} \DecValTok{0}\NormalTok{)}
\NormalTok{cv.out}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:  cv.glmnet(x = x[train, ], y = y[train], alpha = 0) 
## 
## Measure: Mean-Squared Error 
## 
##     Lambda Measure      SE Nonzero
## min  397.4 2103455 1270039      17
## 1se 2554.6 3360297 2169940      17
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Best lambda}
\NormalTok{bestlam <-}\StringTok{ }\NormalTok{cv.out}\OperatorTok{$}\NormalTok{lambda.min}
\NormalTok{bestlam}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 397.4201
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Make predictions}
\NormalTok{OLS.pred <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(OLS_lm, }\DataTypeTok{newdata =}\NormalTok{ College[test,])}
\KeywordTok{head}\NormalTok{(OLS.pred)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        Adelphi University            Adrian College         Albertson College 
##                3350.61158                1397.93516                 608.67123 
##   Albertus Magnus College Alderson-Broaddus College         Allegheny College 
##                  54.98646                 686.22811                2922.74735
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#check Mean Squared Error}
\KeywordTok{mean}\NormalTok{((OLS.pred}\OperatorTok{-}\NormalTok{ytest)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1403054
\end{verbatim}

\end{frame}

\begin{frame}[fragile]{(c) Fit a ridge regression model on the training
set, with λ chosen by cross-validation. Report the test mean squared
error obtained. Report the value of λ used in the model}
\protect\hypertarget{c-fit-a-ridge-regression-model-on-the-training-set-with-ux3bb-chosen-by-cross-validation.-report-the-test-mean-squared-error-obtained.-report-the-value-of-ux3bb-used-in-the-model}{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ridge.mod <-}\StringTok{ }\KeywordTok{glmnet}\NormalTok{(x[train,], y[train], }\DataTypeTok{alpha =} \DecValTok{0}\NormalTok{, }\DataTypeTok{lambda =}\NormalTok{ lambda)}
\KeywordTok{summary}\NormalTok{(ridge.mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Length Class     Mode   
## a0         100   -none-    numeric
## beta      1700   dgCMatrix S4     
## df         100   -none-    numeric
## dim          2   -none-    numeric
## lambda     100   -none-    numeric
## dev.ratio  100   -none-    numeric
## nulldev      1   -none-    numeric
## npasses      1   -none-    numeric
## jerr         1   -none-    numeric
## offset       1   -none-    logical
## call         5   -none-    call   
## nobs         1   -none-    numeric
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Find the best lambda from our list via cross-validation}
\NormalTok{cv.out <-}\StringTok{ }\KeywordTok{cv.glmnet}\NormalTok{(x[train,], y[train], }\DataTypeTok{alpha =} \DecValTok{0}\NormalTok{)}
\NormalTok{cv.out}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:  cv.glmnet(x = x[train, ], y = y[train], alpha = 0) 
## 
## Measure: Mean-Squared Error 
## 
##     Lambda Measure      SE Nonzero
## min  397.4 2352967 1646036      17
## 1se 3077.1 3903384 2937840      17
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Best lambda}
\NormalTok{bestlam <-}\StringTok{ }\NormalTok{cv.out}\OperatorTok{$}\NormalTok{lambda.min}
\NormalTok{bestlam}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 397.4201
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#make predictions}
\NormalTok{ridge.pred <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(ridge.mod, }\DataTypeTok{s =}\NormalTok{ bestlam, }\DataTypeTok{newx =}\NormalTok{ x[test,])}
\KeywordTok{head}\NormalTok{(ridge.pred)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                   1
## Adelphi University        3000.9738
## Adrian College            1164.0138
## Albertson College          595.0114
## Albertus Magnus College    317.8752
## Alderson-Broaddus College  549.4096
## Allegheny College         2677.7668
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Mean squared error}
\KeywordTok{mean}\NormalTok{((ridge.pred}\OperatorTok{-}\NormalTok{ytest)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1298095
\end{verbatim}

\end{frame}

\begin{frame}[fragile]{(d) Fit a lasso model on the training set, with
fraction chosen by cross validation. Report the test mean squared error
obtained, along with the number of non-zero coefficient estimates and
the fraction.}
\protect\hypertarget{d-fit-a-lasso-model-on-the-training-set-with-fraction-chosen-by-cross-validation.-report-the-test-mean-squared-error-obtained-along-with-the-number-of-non-zero-coefficient-estimates-and-the-fraction.}{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso.mod <-}\StringTok{ }\KeywordTok{glmnet}\NormalTok{(x[train,], y[train], }\DataTypeTok{alpha =} \DecValTok{1}\NormalTok{, }\DataTypeTok{lambda =}\NormalTok{ lambda)}
\KeywordTok{summary}\NormalTok{(lasso.mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Length Class     Mode   
## a0         100   -none-    numeric
## beta      1700   dgCMatrix S4     
## df         100   -none-    numeric
## dim          2   -none-    numeric
## lambda     100   -none-    numeric
## dev.ratio  100   -none-    numeric
## nulldev      1   -none-    numeric
## npasses      1   -none-    numeric
## jerr         1   -none-    numeric
## offset       1   -none-    logical
## call         5   -none-    call   
## nobs         1   -none-    numeric
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lasso.pred <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(lasso.mod, }\DataTypeTok{s =}\NormalTok{ bestlam, }\DataTypeTok{newx =}\NormalTok{ x[test,])}
\KeywordTok{head}\NormalTok{(lasso.pred)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                   1
## Adelphi University        2741.3266
## Adrian College            1686.0656
## Albertson College          998.9299
## Albertus Magnus College    629.1303
## Alderson-Broaddus College  875.6115
## Allegheny College         2954.1927
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{((lasso.pred}\OperatorTok{-}\NormalTok{ytest)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1798354
\end{verbatim}

\end{frame}

\begin{frame}[fragile]{(e) Fit a PCR model on the training set, with no.
of principal components M chosen by cross-validation. Report the test
mean squared error obtained, along with the value of M selected by
cross-validation.}
\protect\hypertarget{e-fit-a-pcr-model-on-the-training-set-with-no.-of-principal-components-m-chosen-by-cross-validation.-report-the-test-mean-squared-error-obtained-along-with-the-value-of-m-selected-by-cross-validation.}{}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{smp_size <-}\StringTok{ }\KeywordTok{floor}\NormalTok{(}\FloatTok{0.75} \OperatorTok{*}\StringTok{ }\KeywordTok{nrow}\NormalTok{(mtcars))}
\NormalTok{train_ind <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{seq_len}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(College)), }\DataTypeTok{size =}\NormalTok{ smp_size)}
\NormalTok{train_p <-}\StringTok{ }\NormalTok{College[train_ind, ]}
\NormalTok{test_p <-}\StringTok{ }\NormalTok{College[}\OperatorTok{-}\NormalTok{train_ind,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\OperatorTok{:}\DecValTok{18}\NormalTok{) ]}
\NormalTok{y_test=College[}\OperatorTok{-}\NormalTok{train_ind,}\DecValTok{2}\NormalTok{]}

\KeywordTok{require}\NormalTok{(pls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: pls
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'pls'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:stats':
## 
##     loadings
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pcr_model <-}\StringTok{ }\KeywordTok{pcr}\NormalTok{(Apps}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data =}\NormalTok{ train_p,}\DataTypeTok{scale =}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{validation =} \StringTok{"CV"}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(pcr_model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data:    X dimension: 24 17 
##  Y dimension: 24 1
## Fit method: svdpc
## Number of components considered: 17
## 
## VALIDATION: RMSEP
## Cross-validated using 10 random segments.
##        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
## CV            2426     2779     1375     1389     1371     1509     1612
## adjCV         2426     2749     1351     1365     1342     1477     1568
##        7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
## CV        1605     1625     1842      1786      1664      1373      1346
## adjCV     1559     1574     1779      1714      1606      1305      1282
##        14 comps  15 comps  16 comps  17 comps
## CV         1180     936.9      1293      2503
## adjCV      1126     890.5      1224      2386
## 
## TRAINING: % variance explained
##       1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps
## X       37.40    62.89    73.63    81.16    87.87    91.82    93.96    95.65
## Apps    23.12    81.60    82.53    84.39    86.72    89.36    90.93    91.92
##       9 comps  10 comps  11 comps  12 comps  13 comps  14 comps  15 comps
## X       97.14     97.93     98.65     99.09     99.50     99.79     99.96
## Apps    92.87     95.00     95.49     98.20     98.27     98.44     98.99
##       16 comps  17 comps
## X        99.98    100.00
## Apps     98.99     99.03
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pcr_pred <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(pcr_model, test_p, }\DataTypeTok{ncomp =} \DecValTok{3}\NormalTok{)}
\KeywordTok{head}\NormalTok{(pcr_pred)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1930.6961 1451.1950  704.8014 2322.1893  815.2842 1231.9749
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{((pcr_pred }\OperatorTok{-}\StringTok{ }\NormalTok{y_test)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3664827
\end{verbatim}

\end{frame}

\begin{frame}[fragile]{(f) Fit a PLS model on the training set, with M
chosen by cross validation. Report the test error obtained, along with
the value of M selected by cross-validation.}
\protect\hypertarget{f-fit-a-pls-model-on-the-training-set-with-m-chosen-by-cross-validation.-report-the-test-error-obtained-along-with-the-value-of-m-selected-by-cross-validation.}{}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(caret)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: lattice
\end{verbatim}

\begin{verbatim}
## Loading required package: ggplot2
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'caret'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:pls':
## 
##     R2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Compile cross-validation settings}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{myfolds <-}\StringTok{ }\KeywordTok{createMultiFolds}\NormalTok{(train_p}\OperatorTok{$}\NormalTok{Apps, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{, }\DataTypeTok{times =} \DecValTok{10}\NormalTok{)}
\NormalTok{control <-}\StringTok{ }\KeywordTok{trainControl}\NormalTok{(}\StringTok{"repeatedcv"}\NormalTok{, }\DataTypeTok{index =}\NormalTok{ myfolds, }\DataTypeTok{selectionFunction =} \StringTok{"oneSE"}\NormalTok{)}

\CommentTok{# Train PLS model}
\NormalTok{mod1 <-}\StringTok{ }\KeywordTok{train}\NormalTok{(Apps }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ train_p,}
              \DataTypeTok{method =} \StringTok{"pls"}\NormalTok{,}
              \DataTypeTok{metric =} \StringTok{"RMSE"}\NormalTok{,}
              \DataTypeTok{tuneLength =} \DecValTok{20}\NormalTok{,}
              \DataTypeTok{trControl =}\NormalTok{ control,}
              \DataTypeTok{preProc =} \KeywordTok{c}\NormalTok{(}\StringTok{"zv"}\NormalTok{,}\StringTok{"center"}\NormalTok{,}\StringTok{"scale"}\NormalTok{))}

\KeywordTok{summary}\NormalTok{(mod1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data:    X dimension: 24 17 
##  Y dimension: 24 1
## Fit method: oscorespls
## Number of components considered: 8
## TRAINING: % variance explained
##           1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
## X           30.84    61.11    69.40    75.50    81.94    85.84    89.89
## .outcome    82.50    87.84    92.86    95.44    96.89    97.95    98.46
##           8 comps
## X           94.22
## .outcome    98.71
\end{verbatim}

This displays the metrics in the model including: ncom (number of
predictors which is the value of M), root mean squared error, R-squared,
mean absolute error etc. The lowest RMSE is preferable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod1}\OperatorTok{$}\NormalTok{results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    ncomp      RMSE  Rsquared       MAE    RMSESD RsquaredSD     MAESD
## 1      1 1084.9854 0.7133798  861.7848  521.4875  0.3403221  332.2876
## 2      2 1180.7783 0.7798500  875.6709  564.5886  0.3116584  354.9473
## 3      3 1230.5371 0.7154510  897.1544  561.0249  0.3305893  389.9395
## 4      4 1191.8641 0.7283764  905.3304  475.5401  0.2813624  375.5198
## 5      5 1132.9057 0.7626434  881.3255  443.3958  0.2641401  354.1532
## 6      6 1074.9639 0.7841007  846.2498  384.8527  0.2348362  305.2852
## 7      7 1030.9962 0.8037494  823.7655  344.5840  0.2158111  280.5208
## 8      8  977.8485 0.8270842  799.8415  320.7414  0.1946075  256.7419
## 9      9  961.4021 0.8474581  796.9018  369.8159  0.1860991  279.0550
## 10    10 1003.3505 0.8466150  833.7763  403.9196  0.1928643  310.0666
## 11    11 1066.8502 0.8373313  887.4662  421.3553  0.1989530  320.6783
## 12    12 1137.5497 0.8239245  944.5730  463.5097  0.2021272  351.6782
## 13    13 1229.7565 0.7731685 1007.7498  525.0526  0.2575168  399.2797
## 14    14 1472.4609 0.7342725 1172.4776  702.0939  0.2797465  505.0709
## 15    15 1936.8054 0.6771353 1474.1501 1218.4259  0.3113862  797.1762
## 16    16 2309.6684 0.6659932 1770.6816 1720.6389  0.3131435 1165.2617
\end{verbatim}

\end{frame}

\begin{frame}{(g) Comment on the results obtained. Is there much
difference among the test errors resulting from these five approaches?}
\protect\hypertarget{g-comment-on-the-results-obtained.-is-there-much-difference-among-the-test-errors-resulting-from-these-five-approaches}{}

\begin{itemize}
\tightlist
\item
  There is a noticeable difference between OLS, Ridge, PCR and PLS
  regression in terms of mean squared error whereby Ridge regression had
  the lowest mean squared error followed by PLS, OLS,Lasso and then
  Principal Component Regression had the highest mean squared error.
\end{itemize}

\end{frame}

\end{document}
